
{"optimizer": {
    "class": "torch.optim.Adagrad",
    "parameters": {
        "lr":0.00001
    }
  }
}